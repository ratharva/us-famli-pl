{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from torch.autograd import Function\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "\n",
    "# from loaders.ultrasound_dataset import USDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from loaders.ultrasound_dataset_classification import USDataset\n",
    "from transforms.ultrasound_transforms import USClassEvalTransforms\n",
    "from transferModel import EfficientNetTransfer\n",
    "# from transforms.ultrasound_transforms import USEvalTransforms\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "from captum.attr import GuidedGradCam, GuidedBackprop\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "from captum.attr import visualization as viz\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from torchvision import transforms\n",
    "from monai.transforms import ScaleIntensityRange\n",
    "\n",
    "from pl_bolts.transforms.dataset_normalizations import (\n",
    "    imagenet_normalization\n",
    ")\n",
    "import nrrd\n",
    "from PIL import Image\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import cv2\n",
    "# from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas\n",
    "\n",
    "import pydicom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "import copy\n",
    "import torchvision\n",
    "# from cloneModelArchitectureV3 import EfficientNetClone\n",
    "from cloneModelArchitectureV3Updated import EfficientNetClone\n",
    "from nets.classification_old import EfficientNet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figArr(fig, draw=True):\n",
    "    fig.set_facecolor(\"black\")\n",
    "    myCanvas = fig.canvas#FigureCanvas(fig)\n",
    "    myCanvas.draw()\n",
    "    w, h = myCanvas.get_width_height()#fig.get_size_inches() * fig.get_dpi()\n",
    "    myArr = np.frombuffer(myCanvas.tostring_rgb(), dtype=np.uint8).reshape(h, w, 3)\n",
    "    myImg = cv2.cvtColor(myArr, cv2.COLOR_RGB2BGR)\n",
    "    # plt_fig.grid()\n",
    "    return myImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def useGradcam(myCSV, myModel, myImgCol, myLabels, myNn, myOutFile, myBatchSize, myNumWorkers, myMountPoint, myExtractFeatures):\n",
    "    model = EfficientNetClone(base_encoder=\"efficientnet_b0\").load_from_checkpoint(myModel, strict=False) #, \n",
    "    # model = EfficientNet(base_encoder=\"efficientnet-b0\").load_from_checkpoint(myModel, strict=False)\n",
    "    # modelArch = getattr(torchvision.models, \"efficientnet_b0\")\n",
    "    # model = modelArch(num_classes=6)\n",
    "    print(model)\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    # print(model)\n",
    "    myGuidedGradCam = GuidedGradCam(model, model.efficientnet.convnet.features[8][0])\n",
    "\n",
    "    # myLabelList = ['No structures visible', 'Head Visible',\n",
    "    #             'Abdomen Visible', 'Amniotic fluid visible', \n",
    "    #             'Placenta visible', 'Fetus or CRL visible']\n",
    "    myLabelList = ['No structures visible', 'Head Visible',\n",
    "                'Abdomen Visible', 'Amniotic fluid visible', \n",
    "                'Placenta visible']\n",
    "    if myExtractFeatures:\n",
    "            model.extract_features = True\n",
    "\n",
    "    if(os.path.splitext(myCSV)[1] == \".csv\"):        \n",
    "        df_test = pd.read_csv(os.path.join(myMountPoint, myCSV))\n",
    "    else:        \n",
    "        df_test = pd.read_parquet(os.path.join(myMountPoint, myCSV))\n",
    "        \n",
    "    test_ds = USDataset(df_test, label_column = None, img_column=myImgCol, transform=USClassEvalTransforms(), mount_point=myMountPoint)\n",
    "    test_loader = DataLoader(test_ds, batch_size=myBatchSize, shuffle=False, num_workers=myNumWorkers, pin_memory=True, prefetch_factor=4)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "\n",
    "    transforms.CenterCrop(256),\n",
    "    # ScaleIntensityRange(a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0),\n",
    "\n",
    "    ])\n",
    "    predictions = []\n",
    "    probs = []\n",
    "    features = []\n",
    "    pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    tempCounter = 0\n",
    "    for idx, X in pbar:\n",
    "        if myLabels:\n",
    "            imgTransform = transform(X)\n",
    "        # print(X)\n",
    "        X = X.cuda().contiguous()   \n",
    "        if myExtractFeatures:\n",
    "            # print(\"Does it enter this if2?\")        \n",
    "            pred, x_f = model(X)    \n",
    "            features.append(x_f.cpu().numpy())\n",
    "        else:\n",
    "            # print(\"Does it enter this else?\")\n",
    "            pred = model(X)\n",
    "        myPredSigmoid = nn.Softmax(dim=1)(pred)\n",
    "        converted_tensor = torch.where(myPredSigmoid >= 0.08, torch.tensor(1), torch.tensor(0))\n",
    "        converted_tensor = converted_tensor.cuda()\n",
    "        converted_tensor = np.array(converted_tensor.cpu())\n",
    "        # print(\"Converted Tensor\", converted_tensor)\n",
    "\n",
    "        isInArray = np.any(converted_tensor == 1)\n",
    "        # print(isInArray)\n",
    "        if isInArray:\n",
    "            print(X.squeeze().unsqueeze(0).shape)\n",
    "            oriImag = np.transpose(X.squeeze().unsqueeze(0).cpu().detach().numpy(), (1,2,0))\n",
    "            # print(\"OriImageShape: \", oriImag.shape)\n",
    "\n",
    "            fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "            # Add a subplot to the figure\n",
    "            ax = fig.add_subplot(111)\n",
    "\n",
    "            # Display the oriImag using imshow on the subplot\n",
    "            img_arr = ax.imshow(oriImag)\n",
    "            originalImage = figArr(fig)\n",
    "            tempImage = copy.deepcopy(originalImage)\n",
    "            myDict = {}\n",
    "            myYoloList = []\n",
    "        # print(\"Length of convertedArray: \", len(converted_tensor[0]))\n",
    "        # converted_tensor[0] = converted_tensor[0][1:]\n",
    "        myUUID = uuid.uuid4()\n",
    "        for i in range(len(converted_tensor[0])):\n",
    "            # print(type(converted_tensor[0][i]))\n",
    "            # if converted_tensor[0][0] == 1:\n",
    "            #     continue\n",
    "            # if converted_tensor[0][5] == 1:\n",
    "            #     continue\n",
    "            \n",
    "            if converted_tensor[0][i] == 1:\n",
    "                # if i == 0:\n",
    "                #     continue\n",
    "                # if i == 5:\n",
    "                #     continue\n",
    "                # print(\"i is: \", i)\n",
    "                # print(\"Class is: \", myLabelList[i])\n",
    "                if i == 4:\n",
    "                    tempCounter += 1\n",
    "                    myImageAttributes = myGuidedGradCam.attribute(X, i)\n",
    "                    if np.count_nonzero(myImageAttributes) == 0:\n",
    "                        continue\n",
    "                    top_100_values = np.partition(myImageAttributes, -10)[-10:]\n",
    "                    # Sort the top 100 values in descending order (optional)\n",
    "                    top_100_values_sorted = np.sort(top_100_values)[::-1]\n",
    "                    print(\"Value of image attributes\", top_100_values_sorted)\n",
    "                    # print(\"Image Attributes are: \", np.count_nonzero(myIma\n",
    "                    # cv2.imwrite(\"/mnt/raid/home/ayrisbud/USOD/images/train/whatImage.png\", tempImage)\n",
    "                    # print(myImageAttributes.shape)\n",
    "                    default_cmap = LinearSegmentedColormap.from_list('custom blue', \n",
    "                                                        [(0, '#ffffff'),\n",
    "                                                        (0.25, '#000000'),\n",
    "                                                        (1, '#000000')], N=256)\n",
    "\n",
    "                    myPlt = viz.visualize_image_attr(np.transpose(myImageAttributes.squeeze().unsqueeze(0).cpu().detach().numpy(), (1,2,0)),\n",
    "                                            np.transpose(imgTransform.squeeze().unsqueeze(0).cpu().detach().numpy(), (1,2,0)), \n",
    "                                            \"heat_map\",\n",
    "                                            cmap=\"magma\",\n",
    "                                            # sign=\"absolute_value\",\n",
    "                                            #   show_colorbar=True,\n",
    "                                            # fig_size=(3.56,3.56),\n",
    "                                            use_pyplot=True\n",
    "                                            )\n",
    "                    \n",
    "                    fig, axis = plt.subplots(1, 3, figsize=(30,30))\n",
    "\n",
    "                    myCv2Img = figArr(myPlt[0])\n",
    "                    # cv2.imwrite(\"./tempImagesPres/Heatmap\" + str(idx) + \".jpg\", myCv2Img)\n",
    "                    # originalImage = figArr(myPlt1[0])\n",
    "                    # cv2.imwrite(\"./tempImagesPres/Original\" + str(idx) + \".jpg\", originalImage)\n",
    "                    kernel = np.ones((5, 5), np.uint8)\n",
    "                    # dialatedImg = cv2.dilate(myCv2Img, kernel, iterations=1)\n",
    "                    # plt.axis('off')\n",
    "                    axis[0].imshow(cv2.cvtColor(myCv2Img, cv2.COLOR_BGR2RGB))\n",
    "                    axis[1].imshow(cv2.cvtColor(originalImage, cv2.COLOR_BGR2RGB))\n",
    "                    blendedImage = cv2.addWeighted(myCv2Img,0.5,originalImage,0.7,0)\n",
    "                    axis[2].imshow(cv2.cvtColor(blendedImage, cv2.COLOR_BGR2RGB))\n",
    "                    plt.savefig(\"/mnt/raid/home/ayrisbud/intermediateHeatmapsClone/placenta3/\" + str(tempCounter) + \".png\")\n",
    "                    if tempCounter == 1:\n",
    "                        break\n",
    "                    # myGrayImg = cv2.cvtColor(myCv2Img, cv2.COLOR_BGR2GRAY)\n",
    "                    # myThresh = cv2.threshold(myGrayImg, 30, 255, cv2.THRESH_BINARY)[1]  #+ cv2.THRESH_OTSU\n",
    "                    # dialatedImg = cv2.dilate(myThresh, kernel, iterations=1)\n",
    "                    # # plt.axis('off')\n",
    "                    # # axis[1].imshow(cv2.cvtColor(dialatedImg, cv2.COLOR_BGR2RGB))\n",
    "                    # # cv2.imwrite(\"./tempImagesPres/dialated\" + str(idx) + \".jpg\", dialatedImg)\n",
    "                    # imgCopy = originalImage.copy()\n",
    "                    # imgCopy1 = myCv2Img.copy()\n",
    "                    # # edged = cv2.Canny(dialatedImg, 30, 200)\n",
    "                    # myContours, myHierearchy = cv2.findContours(dialatedImg, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    # sortedConts = sorted(myContours, key=cv2.contourArea, reverse=True)\n",
    "                    # largestContours = sortedConts[0:1]\n",
    "                    # # myContours = myContours[0] if len(myContours) == 2 else myContours[1]\n",
    "                    # contDraw = cv2.drawContours(dialatedImg, largestContours, -1, (255, 255, 0), 3)\n",
    "                    # # axis[2].imshow(cv2.cvtColor(contDraw, cv2.COLOR_BGR2RGB))\n",
    "                    # for cntr in largestContours:\n",
    "                    #     if cv2.arcLength(cntr, True) > 300:\n",
    "                    #         # print(\"ARCLENGTH\", cv2.arcLength(cntr, True))\n",
    "                    #         x,y,w,h = cv2.boundingRect(cntr)\n",
    "                    #         cv2.rectangle(originalImage, (x, y), (x+w, y+h), (36, 255, 12), 2)\n",
    "                    #         x2 = x + w\n",
    "                    #         y2 = y + h\n",
    "                    #         xc = (x + x2) / 2\n",
    "                    #         yc = (y + y2) / 2\n",
    "                    #         nxc = xc / originalImage.shape[0]\n",
    "                    #         nyc = yc / originalImage.shape[1]\n",
    "                    #         nw = w / 600\n",
    "                    #         nh = h / 600\n",
    "                    #         datFormat = f\"{i} {nxc} {nyc} {nw} {nh}\"\n",
    "                    #         # print(\"YOLO FormatData: \", datFormat)\n",
    "                    #         myYoloList.append(datFormat)\n",
    "                    #         myDict[myLabelList[i]] = (nxc, nyc, nw, nh)\n",
    "                    #     # print(\"x,y,w,h:\",x,y,w,h)\n",
    "                    # for cntr in largestContours:\n",
    "                    #     if cv2.arcLength(cntr, True) > 300:\n",
    "                    #         # print(\"ARCLENGTH\", cv2.arcLength(cntr, True))\n",
    "                    #         x,y,w,h = cv2.boundingRect(cntr)\n",
    "                    #         cv2.rectangle(imgCopy1, (x, y), (x+w, y+h), (36, 255, 12), 2)\n",
    "                    #         # print(\"x,y,w,h:\",x,y,w,h)\n",
    "                    # # plt.axis('off')\n",
    "                    # # axis[2].imshow(cv2.cvtColor(imgCopy1, cv2.COLOR_BGR2RGB))\n",
    "                    # # cv2.imwrite(\"./tempImagesPres/heatmapBox\" + str(idx) + \".jpg\", imgCopy1)\n",
    "                    # # plt.axis('off')\n",
    "                    # # axis[3].imshow(cv2.cvtColor(originalImage, cv2.COLOR_BGR2RGB))\n",
    "                    # # tempImage = originalImage\n",
    "                    # # cv2.imwrite(\"./tempImagesPres/OriginalBox\" + str(idx) + \".jpg\", imgCopy)\n",
    "\n",
    "                    # # head, tail = os.path.split(img_path[0])\n",
    "                    # # if not os.path.isdir(\"./gradCamImages/\" + head):\n",
    "                    # #     os.makedirs(\"./gradCamImages/\" + head)\n",
    "            else:\n",
    "                print(\"No Class found!\")\n",
    "        \n",
    "        if tempCounter == 20:\n",
    "            break\n",
    "        # print(myDict)\n",
    "        # print(myYoloList)\n",
    "        # plt.figure(2, figsize=(6,6))\n",
    "        # print(\"ORI IMG DIM: \", originalImage.shape)\n",
    "        # plt.imshow(cv2.cvtColor(originalImage, cv2.COLOR_BGR2RGB))\n",
    "        # print(\"intermediate\")\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "        # print(\"afterPlot\")\n",
    "        # plt.figure(3, figsize=(6,6))\n",
    "        # print(\"ORI IMG DIM: \", tempImage.shape)\n",
    "        # plt.imshow(cv2.cvtColor(tempImage, cv2.COLOR_BGR2RGB))\n",
    "        # print(\"intermediate\")\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "        # print(\"afterPlot\")\n",
    "        # if len(myYoloList) == 0:\n",
    "        #     pass\n",
    "        # else:\n",
    "        #     cv2.imwrite(\"/mnt/raid/home/ayrisbud/USOD/images/test/\" + str(myUUID) + \".png\", tempImage)\n",
    "        #     pathToFile = \"/mnt/raid/home/ayrisbud/USOD/labels/test/\" + str(myUUID) + \".txt\"\n",
    "        #     file = open(pathToFile, \"w+\")\n",
    "        #     for item in myYoloList:\n",
    "        #         file.write(item + \"\\n\")\n",
    "        #     file.close()\n",
    "        \n",
    "        # if idx == 2:\n",
    "        #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    myCSV = \"/mnt/raid/home/ayrisbud/us-famli-pl/src/annotatedTestConcise.csv\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/epoch=21-val_loss=1.06.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/epoch=35-val_loss=1.01.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/epoch=100-val_loss=0.14.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/epoch=20-val_loss=0.418.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/parameter_dw=5/epoch=9-val_loss=0.409.ckpt\" #***\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/parameter_dw=0.05Const3/epoch=8-val_loss=0.410.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/parameter_dw=0.05Const3/epoch=15-val_loss=0.414.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/parameter_dw=0.05Const3/epoch=11-val_loss=0.421.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/parameter_dw=0.05smooth/epoch=8-val_loss=0.397.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/parameter_dw=0.05smooth/epoch=13-val_loss=0.407.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/parameter_dw=0.55/epoch=12-val_loss=0.393.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/noErodeDilute/epoch=17-val_loss=0.411.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/archV3_dw=0.05every5/epoch=9-val_loss=0.410.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/noDice/epoch=12-val_loss=0.414.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/noDice/epoch=15-val_loss=0.408.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/noDice/epoch=19-val_loss=1.016.ckpt\"\n",
    "    # myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/tensorboardImages/epoch=13-val_loss=0.162.ckpt\"\n",
    "    myModel = \"/mnt/raid/home/ayrisbud/train_output/classification/clone/tensorboardImages/epoch=107-val_loss=0.206.ckpt\"\n",
    "    myImgCol = \"img_path\"\n",
    "    myClassCol = \"pred_cluster\"\n",
    "    myNn = \"efficientnet_b0\"    \n",
    "    myOutFile = \"./myOutput\"\n",
    "    myBatchSize = 1\n",
    "    myNumWorkers = 16\n",
    "    myMountPoint = \"/mnt/raid/C1_ML_Analysis/\"\n",
    "    myExtractFeatures = False\n",
    "    myLabels = True\n",
    "    \n",
    "\n",
    "    # main(myCSV, myModel, myImgCol, myClassCol, myNn, myOutFile, myBatchSize, myNumWorkers, myMountPoint, myExtractFeatures)\n",
    "    useGradcam(myCSV=myCSV, myModel=myModel, myImgCol = myImgCol, myNn=myNn, myOutFile=myOutFile, myBatchSize=myBatchSize, myNumWorkers=myNumWorkers, myMountPoint=myMountPoint, myExtractFeatures=myExtractFeatures, myLabels=myLabels)\n",
    "    # useGBackprop(myCSV, myModel, myImgCol, myClassCol, myNn, myOutFile, myBatchSize, myNumWorkers, myMountPoint, myExtractFeatures)\n",
    "    # getBoundingImages(myCSV, myModel, myImgCol, myClassCol, myNn, myOutFile, myBatchSize, myNumWorkers, myMountPoint, myExtractFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_us",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
