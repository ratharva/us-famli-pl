{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision \n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from nets.classification_old import EfficientNet\n",
    "from transferModel import EfficientNetTransfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/raid/home/ayrisbud/anaconda3/envs/torch_us/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:34: UnderReviewWarning: The feature generate_power_seq is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  \"lr_options\": generate_power_seq(LEARNING_RATE_CIFAR, 11),\n",
      "/mnt/raid/home/ayrisbud/anaconda3/envs/torch_us/lib/python3.10/site-packages/pl_bolts/models/self_supervised/amdim/amdim_module.py:92: UnderReviewWarning: The feature FeatureMapContrastiveTask is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  contrastive_task: Union[FeatureMapContrastiveTask] = FeatureMapContrastiveTask(\"01, 02, 11\"),\n",
      "/mnt/raid/home/ayrisbud/anaconda3/envs/torch_us/lib/python3.10/site-packages/pl_bolts/losses/self_supervised_learning.py:228: UnderReviewWarning: The feature AmdimNCELoss is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  self.nce_loss = AmdimNCELoss(tclip)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# from loaders.ultrasound_dataset import USDataset\n",
    "from transforms.ultrasound_transforms import USEvalTransforms\n",
    "from nets.classification import EfficientNet\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "from captum.attr import GuidedGradCam, GuidedBackprop\n",
    "import matplotlib.pyplot as plt\n",
    "from captum.attr import visualization as viz\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from torchvision import transforms\n",
    "from monai.transforms import ScaleIntensityRange\n",
    "\n",
    "from pl_bolts.transforms.dataset_normalizations import (\n",
    "    imagenet_normalization\n",
    ")\n",
    "import nrrd\n",
    "from PIL import Image\n",
    "\n",
    "# from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "# from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "# from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import cv2\n",
    "# from matplotlib.backends.backend_qt4agg import FigureCanvasQTAgg as FigureCanvas\n",
    "\n",
    "# from fastai.vision.all import *\n",
    "# from fastai.medical.imaging import *\n",
    "# from fmi.preprocessing import *\n",
    "# from fmi.train import *\n",
    "# from fmi.examine import *\n",
    "# import pydicom\n",
    "from sklearn.model_selection import train_test_split\n",
    "import uuid\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Missing attribute \"num_classes\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/raid/home/ayrisbud/anaconda3/envs/torch_us/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:296\u001b[0m, in \u001b[0;36mAttributeDict.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[1;32m    297\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exp:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'num_classes'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/mnt/raid/home/ayrisbud/us-famli-pl/src/modelUnderstanding.ipynb Cell 3\u001b[0m in \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfamli-gpu1.med.unc.edu/mnt/raid/home/ayrisbud/us-famli-pl/src/modelUnderstanding.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m myModel \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/mnt/raid/C1_ML_Analysis/train_output/classification/extract_frames_blind_sweeps_c1_30082022_wscores_train_train_sample_clean_feat/epoch=9-val_loss=0.27.ckpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfamli-gpu1.med.unc.edu/mnt/raid/home/ayrisbud/us-famli-pl/src/modelUnderstanding.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# myModel = \"/mnt/raid/C1_ML_Analysis/train_output/classification/extract_frames_blind_sweeps_c1_30082022_wscores_test_w16_kmeans/epoch=5-val_loss=0.53.ckpt\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bfamli-gpu1.med.unc.edu/mnt/raid/home/ayrisbud/us-famli-pl/src/modelUnderstanding.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m model \u001b[39m=\u001b[39m EfficientNet(base_encoder\u001b[39m=\u001b[39;49mmyNn)\u001b[39m.\u001b[39mload_from_checkpoint(myModel)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfamli-gpu1.med.unc.edu/mnt/raid/home/ayrisbud/us-famli-pl/src/modelUnderstanding.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bfamli-gpu1.med.unc.edu/mnt/raid/home/ayrisbud/us-famli-pl/src/modelUnderstanding.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mcuda()\n",
      "File \u001b[0;32m/mnt/raid/home/ayrisbud/us-famli-pl/src/nets/classification.py:45\u001b[0m, in \u001b[0;36mEfficientNet.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_hyperparameters()\n\u001b[1;32m     44\u001b[0m NN \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(torchvision\u001b[39m.\u001b[39mmodels, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mbase_encoder)\n\u001b[0;32m---> 45\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvnet \u001b[39m=\u001b[39m NN(num_classes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhparams\u001b[39m.\u001b[39;49mnum_classes)\n\u001b[1;32m     47\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextract_features \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams, \u001b[39m'\u001b[39m\u001b[39mmodel_feat\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mmodel_feat \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/raid/home/ayrisbud/anaconda3/envs/torch_us/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:298\u001b[0m, in \u001b[0;36mAttributeDict.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m    297\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m exp:\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMissing attribute \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mexp\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Missing attribute \"num_classes\""
     ]
    }
   ],
   "source": [
    "myNn = \"efficientnet_b0\"\n",
    "myModel = \"/mnt/raid/C1_ML_Analysis/train_output/classification/extract_frames_blind_sweeps_c1_30082022_wscores_train_train_sample_clean_feat/epoch=9-val_loss=0.27.ckpt\"\n",
    "# myModel = \"/mnt/raid/C1_ML_Analysis/train_output/classification/extract_frames_blind_sweeps_c1_30082022_wscores_test_w16_kmeans/epoch=5-val_loss=0.53.ckpt\"\n",
    "model = EfficientNet(base_encoder=myNn).load_from_checkpoint(myModel)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_us",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
